{"cells":[{"source":"# Practical Exam: Automating Customer Support with OpenAI API\n\nYou work as an AI Engineer at ChatSolveAI, a company that provides automated customer support solutions. The company wants to improve response times and accuracy in answering customer queries by leveraging OpenAI’s GPT models.\n\nYour task is to build a chatbot that classifies customer queries, retrieves relevant responses, and logs interactions in a structured way. The chatbot will use text embeddings, similarity search, API calls, and conversation management techniques.\n\n\n**Please note:** \n\n1. The OpenAI Embeddings API supports passing a list of strings to the input parameter in a single request. This allows you to generate multiple embeddings at once without looping over individual elements, which can significantly improve efficiency and reduce the risk of hitting rate limits.\n\n2. When submitting your solution, you may see an error message reading 'Something went wrong while submitting your solution. Please try again.' This is because using the OpenAI API may mean code takes longer to run than code in our other Certifications. Please ignore this message if your code is taking a few minutes to run. However, if your code makes too many API requests, the API will time out. If your cells run for more than a few minutes each, you may need to consider revising your code. ","metadata":{},"id":"adb2307c-b472-49f9-a630-7ff34483e7bc","cell_type":"markdown"},{"source":"# Run this cell before running your solution\n\n# Import necessary modules\nimport os\nfrom openai import OpenAI\n\n# Define the model to use\nmodel = \"gpt-3.5-turbo\"\n\n# Define the client\nclient = OpenAI()","metadata":{"executionCancelledAt":null,"executionTime":46,"lastExecutedAt":1767949184220,"lastExecutedByKernel":"2903d6c6-467b-47ea-b370-3f1d4cacbf00","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run this cell before running your solution\n\n# Import necessary modules\nimport os\nfrom openai import OpenAI\n\n# Define the model to use\nmodel = \"gpt-3.5-turbo\"\n\n# Define the client\nclient = OpenAI()"},"id":"e8e08036-f207-45b9-94c2-a79b3795dcd6","cell_type":"code","execution_count":17,"outputs":[]},{"source":"# Task 1\n\nChatSolveAI has provided a knowledge base (`knowledge_base.csv`) containing information about various products, services, and customer policies. To enhance search and query capabilities, you need to convert this data into embeddings and store them for efficient retrieval.\n\n- Load the dataset (`knowledge_base.csv`).\n- Generate text embeddings using OpenAI’s embedding model (`text-embedding-3-small`). Each document's `document_text` should be transformed into an embedding vector. \n- Store the generated embeddings in a structured format (`knowledge_embeddings.json`) with the following format available below.\n- Store the embedded data and associated metadata for retrieval.  \n\n### Format to store generated embeddings:\n```json\n[\n    {\n       \"document_id\": 1,\n       \"document_text\": \"Example document text.\",\n       \"embedding_vector\": [0.123, 0.456, ...],\n       \"metadata\": \"Additional document info\"\n    }\n]\n```\n\n### Data description: \n\n| Column Name       | Criteria                                                |\n|-------------------|---------------------------------------------------------|\n| document_id       | Integer. Unique identifier for each document. No missing values. |\n| document_text     | String. Text content of the knowledge base. Preprocessed and embedded. |\n| embedding_vector  | List. Embedding representation of the `document_text`. |\n| metadata          | String. Metadata for additional information. |\n","metadata":{},"id":"911cf27b","cell_type":"markdown"},{"source":"# =========================\n# TASK 1 — EMBEDDINGS BUILD\n# =========================\n\nimport csv\nimport json\nfrom openai import OpenAI\n\nclient = OpenAI()\n\nINPUT_CSV = \"knowledge_base.csv\"\nOUTPUT_JSON = \"knowledge_embeddings.json\"\nEMBED_MODEL = \"text-embedding-3-small\"\n\ndocuments = []\n\nwith open(INPUT_CSV, newline=\"\", encoding=\"utf-8\") as f:\n    reader = csv.DictReader(f)\n    for row in reader:\n        documents.append({\n            \"document_id\": int(row[\"document_id\"]),\n            \"document_text\": row[\"document_text\"],\n            \"metadata\": row.get(\"metadata\", \"\")\n        })\n\ntexts = [d[\"document_text\"] for d in documents]\n\nembedding_response = client.embeddings.create(\n    model=EMBED_MODEL,\n    input=texts\n)\n\noutput = []\nfor doc, emb in zip(documents, embedding_response.data):\n    output.append({\n        \"document_id\": doc[\"document_id\"],\n        \"document_text\": doc[\"document_text\"],\n        \"embedding_vector\": emb.embedding,\n        \"metadata\": doc[\"metadata\"]\n    })\n\nwith open(OUTPUT_JSON, \"w\", encoding=\"utf-8\") as f:\n    json.dump(output, f, indent=2, ensure_ascii=False)","metadata":{"executionCancelledAt":null,"executionTime":2438,"lastExecutedAt":1767949186659,"lastExecutedByKernel":"2903d6c6-467b-47ea-b370-3f1d4cacbf00","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# =========================\n# TASK 1 — EMBEDDINGS BUILD\n# =========================\n\nimport csv\nimport json\nfrom openai import OpenAI\n\nclient = OpenAI()\n\nINPUT_CSV = \"knowledge_base.csv\"\nOUTPUT_JSON = \"knowledge_embeddings.json\"\nEMBED_MODEL = \"text-embedding-3-small\"\n\ndocuments = []\n\nwith open(INPUT_CSV, newline=\"\", encoding=\"utf-8\") as f:\n    reader = csv.DictReader(f)\n    for row in reader:\n        documents.append({\n            \"document_id\": int(row[\"document_id\"]),\n            \"document_text\": row[\"document_text\"],\n            \"metadata\": row.get(\"metadata\", \"\")\n        })\n\ntexts = [d[\"document_text\"] for d in documents]\n\nembedding_response = client.embeddings.create(\n    model=EMBED_MODEL,\n    input=texts\n)\n\noutput = []\nfor doc, emb in zip(documents, embedding_response.data):\n    output.append({\n        \"document_id\": doc[\"document_id\"],\n        \"document_text\": doc[\"document_text\"],\n        \"embedding_vector\": emb.embedding,\n        \"metadata\": doc[\"metadata\"]\n    })\n\nwith open(OUTPUT_JSON, \"w\", encoding=\"utf-8\") as f:\n    json.dump(output, f, indent=2, ensure_ascii=False)"},"id":"e622234a-8f5f-42f3-9c02-39605971cdbb","cell_type":"code","execution_count":18,"outputs":[]},{"source":"# Task 2\n\nChatSolveAI receives customer queries that need to be classified and matched with appropriate responses. Your task is to preprocess and embed these queries, perform similarity searches on predefined responses (contained in `predefined_responses.json`), and retrieve the most relevant responses.\n\n- Load the dataset (`processed_queries.csv`).\n- Retrieve responses by using cosine similarity to perform a similarity search against predefined responses in `predefined_responses.json`.\n- Structure API requests properly and implement error handling, including retry mechanisms to handle rate limits.\n- Format model responses as JSON to maintain consistency in output.\n- Compute confidence scores for retrieved responses, scaled to 0-1.\n- Store the structured responses in a JSON file (`query_responses.json`), suitable for integration with other applications. Your JSON file should be structured as follows:\n\n| Column Name       | Criteria                                                   |\n|-------------------|------------------------------------------------------------|\n| query_id         | Integer. Unique identifier for each query. No missing values. |\n| query_text       | String. Preprocessed query text. |\n| top_responses    | List. Top 3 most relevant responses retrieved. |\n| confidence_scores | List. Model-based confidence score for the top 3 responses. |","metadata":{},"id":"cc363bc4","cell_type":"markdown"},{"source":"# =========================================\n# TASK 2 — FULLY ROBUST, JSON-AGNOSTIC\n# =========================================\n\nimport csv\nimport json\nimport time\nimport numpy as np\nfrom openai import OpenAI\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# ---------- CONFIG ----------\n\nclient = OpenAI()\n\nQUERY_CSV = \"processed_queries.csv\"\nRESPONSES_JSON = \"predefined_responses.json\"\nOUTPUT_JSON = \"query_responses.json\"\n\nEMBED_MODEL = \"text-embedding-3-small\"\nTOP_K = 3\nCHUNK_SIZE = 100\nRETRY_DELAY = 5\n\n# ---------- EMBEDDING WITH CHUNKING + RETRY ----------\n\ndef embed_texts(texts):\n    \"\"\"Generates embeddings for a list of texts with retry and chunking.\"\"\"\n    embeddings = []\n    for i in range(0, len(texts), CHUNK_SIZE):\n        chunk = texts[i:i + CHUNK_SIZE]\n        if not chunk:\n            continue\n        while True:\n            try:\n                res = client.embeddings.create(\n                    model=EMBED_MODEL,\n                    input=chunk\n                )\n                embeddings.extend([d.embedding for d in res.data])\n                break\n            except Exception:\n                time.sleep(RETRY_DELAY)\n    return np.array(embeddings)\n\n# ---------- LOAD QUERIES ----------\n\nqueries = []\nwith open(QUERY_CSV, newline=\"\", encoding=\"utf-8\") as f:\n    reader = csv.DictReader(f)\n    for row in reader:\n        queries.append({\n            \"query_id\": int(row[\"query_id\"]),\n            \"query_text\": str(row[\"query_text\"]).strip()\n        })\n\nif not queries:\n    raise ValueError(\"No queries loaded from processed_queries.csv\")\n\n# ---------- LOAD & NORMALIZE PREDEFINED RESPONSES ----------\n\nwith open(RESPONSES_JSON, \"r\", encoding=\"utf-8\") as f:\n    raw_data = json.load(f)\n\n# Function to extract any string from an object recursively\ndef extract_strings(obj):\n    strings = []\n    if isinstance(obj, str):\n        if obj.strip():\n            strings.append(obj.strip())\n    elif isinstance(obj, dict):\n        for v in obj.values():\n            strings.extend(extract_strings(v))\n    elif isinstance(obj, list):\n        for item in obj:\n            strings.extend(extract_strings(item))\n    return strings\n\n# Flatten all text from predefined responses\nresponse_texts = extract_strings(raw_data)\n\nif not response_texts:\n    raise ValueError(\"predefined_responses.json contains no usable text\")\n\n# ---------- GENERATE EMBEDDINGS ----------\n\nresponse_embeddings = embed_texts(response_texts)\n\nquery_texts = [q[\"query_text\"] for q in queries]\nquery_embeddings = embed_texts(query_texts)\n\n# ---------- SIMILARITY SEARCH + CONFIDENCE ----------\n\nresults = []\n\nfor q, q_emb in zip(queries, query_embeddings):\n    similarities = cosine_similarity(\n        q_emb.reshape(1, -1),\n        response_embeddings\n    )[0]\n\n    top_indices = similarities.argsort()[-TOP_K:][::-1]\n    top_scores = similarities[top_indices]\n\n    clipped = np.clip(top_scores, 0, None)\n    confidence_scores = (\n        clipped / clipped.max() if clipped.max() > 0 else clipped\n    ).tolist()\n\n    top_responses = [response_texts[i] for i in top_indices]\n\n    results.append({\n        \"query_id\": q[\"query_id\"],\n        \"query_text\": q[\"query_text\"],\n        \"top_responses\": top_responses,\n        \"confidence_scores\": confidence_scores\n    })\n\n# ---------- SAVE OUTPUT ----------\n\nwith open(OUTPUT_JSON, \"w\", encoding=\"utf-8\") as f:\n    json.dump(results, f, indent=2, ensure_ascii=False)","metadata":{"executionCancelledAt":null,"executionTime":4896,"lastExecutedAt":1767949191556,"lastExecutedByKernel":"2903d6c6-467b-47ea-b370-3f1d4cacbf00","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# =========================================\n# TASK 2 — FULLY ROBUST, JSON-AGNOSTIC\n# =========================================\n\nimport csv\nimport json\nimport time\nimport numpy as np\nfrom openai import OpenAI\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# ---------- CONFIG ----------\n\nclient = OpenAI()\n\nQUERY_CSV = \"processed_queries.csv\"\nRESPONSES_JSON = \"predefined_responses.json\"\nOUTPUT_JSON = \"query_responses.json\"\n\nEMBED_MODEL = \"text-embedding-3-small\"\nTOP_K = 3\nCHUNK_SIZE = 100\nRETRY_DELAY = 5\n\n# ---------- EMBEDDING WITH CHUNKING + RETRY ----------\n\ndef embed_texts(texts):\n    \"\"\"Generates embeddings for a list of texts with retry and chunking.\"\"\"\n    embeddings = []\n    for i in range(0, len(texts), CHUNK_SIZE):\n        chunk = texts[i:i + CHUNK_SIZE]\n        if not chunk:\n            continue\n        while True:\n            try:\n                res = client.embeddings.create(\n                    model=EMBED_MODEL,\n                    input=chunk\n                )\n                embeddings.extend([d.embedding for d in res.data])\n                break\n            except Exception:\n                time.sleep(RETRY_DELAY)\n    return np.array(embeddings)\n\n# ---------- LOAD QUERIES ----------\n\nqueries = []\nwith open(QUERY_CSV, newline=\"\", encoding=\"utf-8\") as f:\n    reader = csv.DictReader(f)\n    for row in reader:\n        queries.append({\n            \"query_id\": int(row[\"query_id\"]),\n            \"query_text\": str(row[\"query_text\"]).strip()\n        })\n\nif not queries:\n    raise ValueError(\"No queries loaded from processed_queries.csv\")\n\n# ---------- LOAD & NORMALIZE PREDEFINED RESPONSES ----------\n\nwith open(RESPONSES_JSON, \"r\", encoding=\"utf-8\") as f:\n    raw_data = json.load(f)\n\n# Function to extract any string from an object recursively\ndef extract_strings(obj):\n    strings = []\n    if isinstance(obj, str):\n        if obj.strip():\n            strings.append(obj.strip())\n    elif isinstance(obj, dict):\n        for v in obj.values():\n            strings.extend(extract_strings(v))\n    elif isinstance(obj, list):\n        for item in obj:\n            strings.extend(extract_strings(item))\n    return strings\n\n# Flatten all text from predefined responses\nresponse_texts = extract_strings(raw_data)\n\nif not response_texts:\n    raise ValueError(\"predefined_responses.json contains no usable text\")\n\n# ---------- GENERATE EMBEDDINGS ----------\n\nresponse_embeddings = embed_texts(response_texts)\n\nquery_texts = [q[\"query_text\"] for q in queries]\nquery_embeddings = embed_texts(query_texts)\n\n# ---------- SIMILARITY SEARCH + CONFIDENCE ----------\n\nresults = []\n\nfor q, q_emb in zip(queries, query_embeddings):\n    similarities = cosine_similarity(\n        q_emb.reshape(1, -1),\n        response_embeddings\n    )[0]\n\n    top_indices = similarities.argsort()[-TOP_K:][::-1]\n    top_scores = similarities[top_indices]\n\n    clipped = np.clip(top_scores, 0, None)\n    confidence_scores = (\n        clipped / clipped.max() if clipped.max() > 0 else clipped\n    ).tolist()\n\n    top_responses = [response_texts[i] for i in top_indices]\n\n    results.append({\n        \"query_id\": q[\"query_id\"],\n        \"query_text\": q[\"query_text\"],\n        \"top_responses\": top_responses,\n        \"confidence_scores\": confidence_scores\n    })\n\n# ---------- SAVE OUTPUT ----------\n\nwith open(OUTPUT_JSON, \"w\", encoding=\"utf-8\") as f:\n    json.dump(results, f, indent=2, ensure_ascii=False)"},"id":"b0a8525a-4279-4c1c-8d94-3780b6799355","cell_type":"code","execution_count":19,"outputs":[]},{"source":"# Task 3\n\nTo provide seamless customer service, ChatSolveAI wants to develop a chatbot that can respond to customer queries efficiently by searching for relevant responses and generating new ones when necessary.\n\n- Develop a chatbot that:\n    - Accepts customer queries via text input.\n    - Searches for the most relevant responses from a predefined set of responses (`chatbot_responses.json`).\n    - Uses the OpenAI Embeddings API (`text-embedding-3-small`) to compute semantic similarity between queries.\n    - If no relevant response is found from the predefined set, generates a new response using GPT-3.5-turbo.\n- Stores conversation history, including:\n    - Query text\n    - Retrieved response\n    - Timestamp of the interaction\n    - Confidence score of the response\n- Include one open-ended query not in the predefined responses (e.g., about the refund policy) to test the chatbot’s ability to handle unmatched queries.\n- Include one paraphrased query about support hours (e.g., “When can I talk to someone from support?”) to test semantic similarity matching.\n- Store structured chatbot responses in a JSON file (`sample_chatbot_responses.json`). Make sure they follow this format:\n```json\n[\n    {\n        \"query_text\": \"How do I reset my password?\",\n        \"retrieved_response\": \"You can reset your password by clicking 'Forgot Password' on the login page.\",\n        \"timestamp\": \"2025-04-02T14:30:00Z\",\n        \"confidence_score\": 0.92\n    },\n    {\n        \"query_text\": \"What are your business hours?\",\n        \"retrieved_response\": \"Our support team is available from 9 AM to 5 PM, Monday to Friday.\",\n        \"timestamp\": \"2025-04-02T14:35:00Z\",\n        \"confidence_score\": 0.87\n    }\n]\n```","metadata":{},"id":"01aca3b9","cell_type":"markdown"},{"source":"# =========================================\n# TASK 3 — CHATBOT WITH HISTORY AND GPT FALLBACK\n# =========================================\n\nimport json\nimport time\nfrom datetime import datetime, timezone\nimport numpy as np\nfrom openai import OpenAI\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# ---------- CONFIG ----------\n\nclient = OpenAI()\n\nRESPONSES_JSON = \"chatbot_responses.json\"\nOUTPUT_JSON = \"sample_chatbot_responses.json\"\n\nEMBED_MODEL = \"text-embedding-3-small\"\nCHAT_MODEL = \"gpt-3.5-turbo\"\nTOP_K = 1  # only need top 1 for chatbot reply\nCONFIDENCE_THRESHOLD = 0.6  # if similarity < threshold, call GPT\nRETRY_DELAY = 5\n\n# ---------- EMBEDDING WITH RETRY ----------\n\ndef embed_texts(texts):\n    embeddings = []\n    for text in texts:\n        while True:\n            try:\n                res = client.embeddings.create(\n                    model=EMBED_MODEL,\n                    input=text\n                )\n                embeddings.append(res.data[0].embedding)\n                break\n            except Exception:\n                time.sleep(RETRY_DELAY)\n    return np.array(embeddings)\n\n# ---------- LOAD & NORMALIZE PREDEFINED RESPONSES ----------\n\nwith open(RESPONSES_JSON, \"r\", encoding=\"utf-8\") as f:\n    raw = json.load(f)\n\ndef extract_strings(obj):\n    strings = []\n    if isinstance(obj, str):\n        if obj.strip():\n            strings.append(obj.strip())\n    elif isinstance(obj, dict):\n        for v in obj.values():\n            strings.extend(extract_strings(v))\n    elif isinstance(obj, list):\n        for item in obj:\n            strings.extend(extract_strings(item))\n    return strings\n\npredefined_texts = extract_strings(raw)\nif not predefined_texts:\n    raise ValueError(\"chatbot_responses.json contains no usable text\")\n\n# Embed predefined responses\nresponse_embeddings = embed_texts(predefined_texts)\n\n# ---------- CHATBOT FUNCTION ----------\n\ndef get_chatbot_response(query_text):\n    # Embed the query\n    query_emb = embed_texts([query_text])[0]\n\n    # Compute cosine similarity\n    sims = cosine_similarity(query_emb.reshape(1, -1), response_embeddings)[0]\n    top_idx = sims.argmax()\n    top_score = sims[top_idx]\n    retrieved_response = predefined_texts[top_idx]\n\n    # Decide whether to use GPT fallback\n    if top_score < CONFIDENCE_THRESHOLD:\n        # Generate GPT response\n        prompt = f\"Customer query: {query_text}\\nProvide a helpful, concise response.\"\n        gpt_resp = client.chat.completions.create(\n            model=CHAT_MODEL,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            temperature=0.7\n        )\n        retrieved_response = gpt_resp.choices[0].message.content.strip()\n        confidence_score = 0.5  # fallback default confidence\n    else:\n        confidence_score = float(np.clip(top_score, 0, 1))\n\n    # Timestamp in UTC ISO format\n    timestamp = datetime.now(timezone.utc).isoformat()\n\n    return {\n        \"query_text\": query_text,\n        \"retrieved_response\": retrieved_response,\n        \"timestamp\": timestamp,\n        \"confidence_score\": confidence_score\n    }\n\n# ---------- SAMPLE TEST QUERIES ----------\n\ntest_queries = [\n    \"How do I reset my password?\",  # matches predefined\n    \"When can I talk to someone from support?\",  # paraphrased support hours\n    \"Can I get a refund if I return the item?\"  # open-ended, likely GPT\n]\n\nchat_history = []\nfor q in test_queries:\n    chat_history.append(get_chatbot_response(q))\n\n# ---------- SAVE CHAT HISTORY ----------\n\nwith open(OUTPUT_JSON, \"w\", encoding=\"utf-8\") as f:\n    json.dump(chat_history, f, indent=2, ensure_ascii=False)","metadata":{"executionCancelledAt":null,"executionTime":19642,"lastExecutedAt":1767949211200,"lastExecutedByKernel":"2903d6c6-467b-47ea-b370-3f1d4cacbf00","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# =========================================\n# TASK 3 — CHATBOT WITH HISTORY AND GPT FALLBACK\n# =========================================\n\nimport json\nimport time\nfrom datetime import datetime, timezone\nimport numpy as np\nfrom openai import OpenAI\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# ---------- CONFIG ----------\n\nclient = OpenAI()\n\nRESPONSES_JSON = \"chatbot_responses.json\"\nOUTPUT_JSON = \"sample_chatbot_responses.json\"\n\nEMBED_MODEL = \"text-embedding-3-small\"\nCHAT_MODEL = \"gpt-3.5-turbo\"\nTOP_K = 1  # only need top 1 for chatbot reply\nCONFIDENCE_THRESHOLD = 0.6  # if similarity < threshold, call GPT\nRETRY_DELAY = 5\n\n# ---------- EMBEDDING WITH RETRY ----------\n\ndef embed_texts(texts):\n    embeddings = []\n    for text in texts:\n        while True:\n            try:\n                res = client.embeddings.create(\n                    model=EMBED_MODEL,\n                    input=text\n                )\n                embeddings.append(res.data[0].embedding)\n                break\n            except Exception:\n                time.sleep(RETRY_DELAY)\n    return np.array(embeddings)\n\n# ---------- LOAD & NORMALIZE PREDEFINED RESPONSES ----------\n\nwith open(RESPONSES_JSON, \"r\", encoding=\"utf-8\") as f:\n    raw = json.load(f)\n\ndef extract_strings(obj):\n    strings = []\n    if isinstance(obj, str):\n        if obj.strip():\n            strings.append(obj.strip())\n    elif isinstance(obj, dict):\n        for v in obj.values():\n            strings.extend(extract_strings(v))\n    elif isinstance(obj, list):\n        for item in obj:\n            strings.extend(extract_strings(item))\n    return strings\n\npredefined_texts = extract_strings(raw)\nif not predefined_texts:\n    raise ValueError(\"chatbot_responses.json contains no usable text\")\n\n# Embed predefined responses\nresponse_embeddings = embed_texts(predefined_texts)\n\n# ---------- CHATBOT FUNCTION ----------\n\ndef get_chatbot_response(query_text):\n    # Embed the query\n    query_emb = embed_texts([query_text])[0]\n\n    # Compute cosine similarity\n    sims = cosine_similarity(query_emb.reshape(1, -1), response_embeddings)[0]\n    top_idx = sims.argmax()\n    top_score = sims[top_idx]\n    retrieved_response = predefined_texts[top_idx]\n\n    # Decide whether to use GPT fallback\n    if top_score < CONFIDENCE_THRESHOLD:\n        # Generate GPT response\n        prompt = f\"Customer query: {query_text}\\nProvide a helpful, concise response.\"\n        gpt_resp = client.chat.completions.create(\n            model=CHAT_MODEL,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            temperature=0.7\n        )\n        retrieved_response = gpt_resp.choices[0].message.content.strip()\n        confidence_score = 0.5  # fallback default confidence\n    else:\n        confidence_score = float(np.clip(top_score, 0, 1))\n\n    # Timestamp in UTC ISO format\n    timestamp = datetime.now(timezone.utc).isoformat()\n\n    return {\n        \"query_text\": query_text,\n        \"retrieved_response\": retrieved_response,\n        \"timestamp\": timestamp,\n        \"confidence_score\": confidence_score\n    }\n\n# ---------- SAMPLE TEST QUERIES ----------\n\ntest_queries = [\n    \"How do I reset my password?\",  # matches predefined\n    \"When can I talk to someone from support?\",  # paraphrased support hours\n    \"Can I get a refund if I return the item?\"  # open-ended, likely GPT\n]\n\nchat_history = []\nfor q in test_queries:\n    chat_history.append(get_chatbot_response(q))\n\n# ---------- SAVE CHAT HISTORY ----------\n\nwith open(OUTPUT_JSON, \"w\", encoding=\"utf-8\") as f:\n    json.dump(chat_history, f, indent=2, ensure_ascii=False)"},"id":"3282c024-5414-4c3b-8e7b-06695175652d","cell_type":"code","execution_count":20,"outputs":[]},{"source":"import json\nimport os\nfrom datetime import datetime\n\n# ---------- FILE PATHS ----------\n\nTASK1_JSON = \"knowledge_embeddings.json\"\nTASK2_JSON = \"query_responses.json\"\nTASK3_JSON = \"sample_chatbot_responses.json\"\n\nerrors = []\n\n# ---------- TASK 1 VALIDATION ----------\n\nif not os.path.exists(TASK1_JSON):\n    errors.append(\"Task 1 JSON file not found.\")\nelse:\n    with open(TASK1_JSON, \"r\", encoding=\"utf-8\") as f:\n        task1_data = json.load(f)\n    for i, doc in enumerate(task1_data):\n        if not all(k in doc for k in [\"document_id\", \"document_text\", \"embedding_vector\", \"metadata\"]):\n            errors.append(f\"Task 1: Missing keys in document {i}.\")\n        if not isinstance(doc[\"embedding_vector\"], list):\n            errors.append(f\"Task 1: embedding_vector not a list in document {i}.\")\n        if not isinstance(doc[\"document_id\"], int):\n            errors.append(f\"Task 1: document_id not int in document {i}.\")\n\n# ---------- TASK 2 VALIDATION ----------\n\nif not os.path.exists(TASK2_JSON):\n    errors.append(\"Task 2 JSON file not found.\")\nelse:\n    with open(TASK2_JSON, \"r\", encoding=\"utf-8\") as f:\n        task2_data = json.load(f)\n    for i, entry in enumerate(task2_data):\n        # Check keys\n        if not all(k in entry for k in [\"query_id\", \"query_text\", \"top_responses\", \"confidence_scores\"]):\n            errors.append(f\"Task 2: Missing keys in entry {i}.\")\n        # Check top_responses\n        if not isinstance(entry[\"top_responses\"], list) or len(entry[\"top_responses\"]) != 3:\n            errors.append(f\"Task 2: top_responses must be a list of 3 in entry {i}.\")\n        # Check confidence scores\n        scores = entry.get(\"confidence_scores\", [])\n        if not isinstance(scores, list) or len(scores) != 3:\n            errors.append(f\"Task 2: confidence_scores must be a list of 3 in entry {i}.\")\n        for score in scores:\n            if not (0 <= score <= 1):\n                errors.append(f\"Task 2: confidence score {score} out of range in entry {i}.\")\n\n# ---------- TASK 3 VALIDATION ----------\n\nif not os.path.exists(TASK3_JSON):\n    errors.append(\"Task 3 JSON file not found.\")\nelse:\n    with open(TASK3_JSON, \"r\", encoding=\"utf-8\") as f:\n        task3_data = json.load(f)\n    for i, entry in enumerate(task3_data):\n        # Check keys\n        if not all(k in entry for k in [\"query_text\", \"retrieved_response\", \"timestamp\", \"confidence_score\"]):\n            errors.append(f\"Task 3: Missing keys in entry {i}.\")\n        # Check confidence_score\n        score = entry.get(\"confidence_score\", -1)\n        if not (0 <= score <= 1):\n            errors.append(f\"Task 3: confidence_score out of range in entry {i}.\")\n        # Check timestamp format\n        try:\n            datetime.fromisoformat(entry[\"timestamp\"])\n        except Exception:\n            errors.append(f\"Task 3: Invalid timestamp format in entry {i}.\")\n\n# ---------- FINAL REPORT ----------\n\nif not errors:\n    print(\"All tasks validated successfully! ✅\")\nelse:\n    print(\"Validation errors found:\")\n    for e in errors:\n        print(\"-\", e)","metadata":{"executionCancelledAt":null,"executionTime":367,"lastExecutedAt":1767949211569,"lastExecutedByKernel":"2903d6c6-467b-47ea-b370-3f1d4cacbf00","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import json\nimport os\nfrom datetime import datetime\n\n# ---------- FILE PATHS ----------\n\nTASK1_JSON = \"knowledge_embeddings.json\"\nTASK2_JSON = \"query_responses.json\"\nTASK3_JSON = \"sample_chatbot_responses.json\"\n\nerrors = []\n\n# ---------- TASK 1 VALIDATION ----------\n\nif not os.path.exists(TASK1_JSON):\n    errors.append(\"Task 1 JSON file not found.\")\nelse:\n    with open(TASK1_JSON, \"r\", encoding=\"utf-8\") as f:\n        task1_data = json.load(f)\n    for i, doc in enumerate(task1_data):\n        if not all(k in doc for k in [\"document_id\", \"document_text\", \"embedding_vector\", \"metadata\"]):\n            errors.append(f\"Task 1: Missing keys in document {i}.\")\n        if not isinstance(doc[\"embedding_vector\"], list):\n            errors.append(f\"Task 1: embedding_vector not a list in document {i}.\")\n        if not isinstance(doc[\"document_id\"], int):\n            errors.append(f\"Task 1: document_id not int in document {i}.\")\n\n# ---------- TASK 2 VALIDATION ----------\n\nif not os.path.exists(TASK2_JSON):\n    errors.append(\"Task 2 JSON file not found.\")\nelse:\n    with open(TASK2_JSON, \"r\", encoding=\"utf-8\") as f:\n        task2_data = json.load(f)\n    for i, entry in enumerate(task2_data):\n        # Check keys\n        if not all(k in entry for k in [\"query_id\", \"query_text\", \"top_responses\", \"confidence_scores\"]):\n            errors.append(f\"Task 2: Missing keys in entry {i}.\")\n        # Check top_responses\n        if not isinstance(entry[\"top_responses\"], list) or len(entry[\"top_responses\"]) != 3:\n            errors.append(f\"Task 2: top_responses must be a list of 3 in entry {i}.\")\n        # Check confidence scores\n        scores = entry.get(\"confidence_scores\", [])\n        if not isinstance(scores, list) or len(scores) != 3:\n            errors.append(f\"Task 2: confidence_scores must be a list of 3 in entry {i}.\")\n        for score in scores:\n            if not (0 <= score <= 1):\n                errors.append(f\"Task 2: confidence score {score} out of range in entry {i}.\")\n\n# ---------- TASK 3 VALIDATION ----------\n\nif not os.path.exists(TASK3_JSON):\n    errors.append(\"Task 3 JSON file not found.\")\nelse:\n    with open(TASK3_JSON, \"r\", encoding=\"utf-8\") as f:\n        task3_data = json.load(f)\n    for i, entry in enumerate(task3_data):\n        # Check keys\n        if not all(k in entry for k in [\"query_text\", \"retrieved_response\", \"timestamp\", \"confidence_score\"]):\n            errors.append(f\"Task 3: Missing keys in entry {i}.\")\n        # Check confidence_score\n        score = entry.get(\"confidence_score\", -1)\n        if not (0 <= score <= 1):\n            errors.append(f\"Task 3: confidence_score out of range in entry {i}.\")\n        # Check timestamp format\n        try:\n            datetime.fromisoformat(entry[\"timestamp\"])\n        except Exception:\n            errors.append(f\"Task 3: Invalid timestamp format in entry {i}.\")\n\n# ---------- FINAL REPORT ----------\n\nif not errors:\n    print(\"All tasks validated successfully! ✅\")\nelse:\n    print(\"Validation errors found:\")\n    for e in errors:\n        print(\"-\", e)","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"fb2f0078-92f1-401e-b807-30799cb70426","outputs":[{"output_type":"stream","name":"stdout","text":"All tasks validated successfully! ✅\n"}],"execution_count":21}],"metadata":{"editor":"DataLab","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}